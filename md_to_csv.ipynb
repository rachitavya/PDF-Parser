{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "boaMNedOqnlN",
   "metadata": {
    "id": "boaMNedOqnlN",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initializing chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f491bd9",
   "metadata": {
    "id": "1f491bd9",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01ma\u001b[39;00m\n\u001b[0;32m      2\u001b[0m file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput/md/hindi/Natural_Farming_Kharif_Booklet.md\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m md_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mopen\u001b[39m(file_name,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'a'"
     ]
    }
   ],
   "source": [
    "import a\n",
    "file_name='input/md/hindi/Natural_Farming_Kharif_Booklet.md'\n",
    "md_file=open(file_name,'r',encoding='utf-8')\n",
    "md=md_file.read()\n",
    "chunks=md.split('\\n')\n",
    "\n",
    "# chunks=[chunk for chunk in chunks if chunk!='']\n",
    "# for chunk in chunks:\n",
    "#     print(chunk,end='\\n*****\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8226e93-a02e-4815-b8cb-a4f0c9584e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5255f64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "a5255f64",
    "outputId": "559c9c93-0be4-46d5-c855-661fe81c147a",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db1e16-58f5-43a3-87a4-48b35f2e8567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafc398",
   "metadata": {
    "editable": true,
    "id": "7dafc398",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def table_parser(chunks,index):\n",
    "    inside_table = False\n",
    "    current_table = ''\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        if inside_table:\n",
    "            # Check if the current chunk is the end of the tablere\n",
    "            if chunk.startswith('|') :\n",
    "                inside_table = True\n",
    "                current_table=current_table+'\\n'+chunk\n",
    "            else:\n",
    "\n",
    "                return current_table,(index+i)\n",
    "        elif chunk.startswith('|'):\n",
    "            inside_table = True\n",
    "            current_table=chunk\n",
    "    #     elif chunk=='':\n",
    "    #         continue\n",
    "#         else:\n",
    "#             print('post',(index+i))\n",
    "#             return combined_chunks,(index+i)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def para_parser(chunks,index):\n",
    "    inside_para=False\n",
    "    current_para=''\n",
    "    temp=['#','## ','### ','#### ','##### ','###### ','-','|']\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        if chunk=='':\n",
    "            i=i+1            \n",
    "        elif inside_para:\n",
    "            if chunk[0] not in temp:\n",
    "                inside_para=True\n",
    "                current_para=current_para+' '+chunk\n",
    "            else:\n",
    "                current_para=current_para.strip()\n",
    "                # if len(current_para)==0:\n",
    "                #     return(current_para,'flag')\n",
    "                return (current_para,(index+i))            \n",
    "        elif (chunk[0] not in temp) or chunk!='|':\n",
    "            inside_para=True\n",
    "            current_para=chunk\n",
    "            \n",
    "    return (current_para,(index+i))\n",
    "\n",
    "def list_parser(chunks,index):\n",
    "    inside_list=False\n",
    "    current_list=''\n",
    "    temp=['#','## ','### ','#### ','##### ','###### ','-','|']\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        if inside_list:\n",
    "            if chunk=='' or chunk.startswith('- ') or chunk.startswith('* '):\n",
    "                return (current_list,(index+i))\n",
    "            if chunk[0] not in temp:\n",
    "                current_list=current_list+'\\n'+chunk\n",
    "        elif chunk.startswith('-') or chunk.startswith('* '):\n",
    "            current_list=chunk\n",
    "            inside_list=True\n",
    "\n",
    "    return (current_list,(index+i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U_ppWc4lqxey",
   "metadata": {
    "id": "U_ppWc4lqxey",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Extracting types for chunks and creating a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94867fa6",
   "metadata": {
    "editable": true,
    "id": "94867fa6",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(len(chunks)):\n",
    "i=0\n",
    "combined_chunks=[]\n",
    "temp=['#','## ','### ','#### ','##### ','###### ','-','*','|']\n",
    "while i<len(chunks):\n",
    "    if chunks[i]=='':\n",
    "        combined_chunks.append({'type':'return','content':chunks[i]})\n",
    "        i=i+1\n",
    "    elif chunks[i].startswith('|') and len(chunks[i])!=1:\n",
    "        chunk,i=table_parser(chunks[i:],i)\n",
    "        combined_chunks.append({'type':'table','content':chunk})\n",
    "\n",
    "    elif chunks[i].startswith('# ') or chunks[i].startswith('## ') or chunks[i].startswith('### ') or chunks[i].startswith('#### ') or chunks[i].startswith('##### '):\n",
    "        combined_chunks.append({'type':'heading','content':chunks[i]})\n",
    "        i=i+1\n",
    "\n",
    "    elif chunks[i].startswith('- ') or chunks[i].startswith('* '):\n",
    "        chunk,i=para_parser(chunks[i:],i)\n",
    "        combined_chunks.append({'type':'list','content':chunk})\n",
    "\n",
    "    elif (chunks[i][0] not in temp and (i+1)!=len(chunks)) or chunks[i]=='|':\n",
    "        chunk,i=para_parser(chunks[i:],i)\n",
    "            \n",
    "            # chunk=chunks[i].strip()\n",
    "        if len(chunk)==0:\n",
    "                \n",
    "                continue\n",
    "        combined_chunks.append({'type':'para','content':chunk})\n",
    "            # i=i+1\n",
    "    else:\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947f4d6",
   "metadata": {
    "editable": true,
    "id": "f947f4d6",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_chunks = [chunk for chunk in combined_chunks if chunk['type'] != 'return']\n",
    "# combined_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b4786-e4c1-4018-bef1-27c321929bae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd290448",
   "metadata": {
    "id": "bd290448"
   },
   "outputs": [],
   "source": [
    "inside_pair=False\n",
    "paired_chunks=[]\n",
    "current_pair={'type':'heading-para pair','content':{}}\n",
    "for chunk in combined_chunks:\n",
    "    if chunk['type']=='heading':\n",
    "        inside_pair=True\n",
    "        current_pair['content']['heading']=chunk['content']\n",
    "    elif chunk['type']=='para':\n",
    "        if inside_pair:\n",
    "            current_pair['content']['para']=chunk['content']\n",
    "            paired_chunks.append(current_pair)\n",
    "            inside_pair=False\n",
    "            current_pair={'type':'heading-para pair','content':{}}\n",
    "        else:\n",
    "            paired_chunks.append(chunk)\n",
    "    else:\n",
    "        paired_chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed3e03",
   "metadata": {
    "id": "12ed3e03"
   },
   "outputs": [],
   "source": [
    "# def count_level(content):\n",
    "#     level\n",
    "#     if content.startswith('# '):\n",
    "#         level=1\n",
    "#     elif content.startswith('## '):\n",
    "#         level=2\n",
    "#     elif content.startswith('### '):\n",
    "#         level=3\n",
    "#     elif content.startswith('#### '):\n",
    "#         level=4\n",
    "#     elif content.startswith('##### '):\n",
    "#         level=5\n",
    "#     elif content.startswith('###### '):\n",
    "#         level=6\n",
    "\n",
    "\n",
    "#     return level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wfdQJ2kyq7_8",
   "metadata": {
    "id": "wfdQJ2kyq7_8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Creating heading heirarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf81eb",
   "metadata": {
    "id": "3cbf81eb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assign_ids_and_parents(chunks):\n",
    "    id_counter = {'1': 0, '2': 0, '3': 0,'4':0,'5':0}\n",
    "    parent_stack = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if chunk['type'] == 'heading':\n",
    "            level = chunk['content'].count('#')\n",
    "#             level=count_level(chunk['content'])\n",
    "#             print('hehe',level)\n",
    "            id_counter[str(level)] += 1\n",
    "            chunk['id'] = f'{level}{id_counter[str(level)]}'\n",
    "\n",
    "            if parent_stack==[] or level==1:\n",
    "                parent_stack = [chunk['id']]\n",
    "            else:\n",
    "                buff=int(str(parent_stack[0])[0])-1\n",
    "                while len(parent_stack)>=(level-buff):\n",
    "                    parent_stack.pop()\n",
    "                parent_stack.append(chunk['id'])\n",
    "            chunk['parents'] = parent_stack[:-1]\n",
    "#             print(parent_stack)\n",
    "\n",
    "        else:\n",
    "            chunk['parents'] = parent_stack.copy() if parent_stack else []\n",
    "\n",
    "    return chunks\n",
    "final_chunks=assign_ids_and_parents(combined_chunks)\n",
    "final_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da056dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2da056dc",
    "outputId": "f2ba0eab-3330-4830-9048-850f0d3facdc"
   },
   "outputs": [],
   "source": [
    "len(final_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pOQgJCzxqhxJ",
   "metadata": {
    "id": "pOQgJCzxqhxJ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Creating CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd20c5",
   "metadata": {
    "id": "1cfd20c5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headings={}\n",
    "for chunk in final_chunks:\n",
    "    if chunk['type']=='heading':\n",
    "        headings[chunk['id']]=chunk['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tDljYTEMh7HE",
   "metadata": {
    "id": "tDljYTEMh7HE"
   },
   "outputs": [],
   "source": [
    "def get_subheading(chunks,index):\n",
    "  subheadings=''\n",
    "  for heading in chunks[index]['parents']:\n",
    "    subheadings+=(' '.join(headings[heading].split()[1:]))+','\n",
    "  return subheadings[:-1]\n",
    "\n",
    "import csv\n",
    "#CSV columns: chunkId,content,StartPage,EndPage,heading,ContentWordCount,pdfName,contentType,image,summary\n",
    "def export_csv(final_chunks):\n",
    "\n",
    "  with open('output.csv','w') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    data=['chunkId','content','StartPage','EndPage','heading','ContentWordCount','pdfName','contentType','image','summary']\n",
    "    csv_writer.writerow(data)\n",
    "\n",
    "  for i,chunk in enumerate(final_chunks):\n",
    "    chunkId=i+1\n",
    "    content=chunk['content']\n",
    "    heading=get_subheading(final_chunks,i)\n",
    "    contentType=chunk['type']\n",
    "    ContentWordCount=len(content.split()) if contentType!='table' else content.split('|')\n",
    "    pdfName=file_name.split('.')[0]+'.pdf'\n",
    "    data=[chunkId,content,'','',heading,ContentWordCount,pdfName,contentType,'','']\n",
    "    with open('output.csv','a',encoding='utf-8') as file:\n",
    "      csv_writer = csv.writer(file)\n",
    "      csv_writer.writerow(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7f886-34a9-4808-a9b1-23f68baec84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_string = \"This is a simple string.\"\n",
    "\n",
    "# Split the string into words, add a space after each word, and join them\n",
    "modified_string = ' '.join(original_string.split()[1:])\n",
    "\n",
    "# Display the modified string\n",
    "print(modified_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0QDxUqP_nnTk",
   "metadata": {
    "id": "0QDxUqP_nnTk"
   },
   "outputs": [],
   "source": [
    "export_csv(final_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf208053-bdef-4749-b656-6568bf7238bd",
   "metadata": {
    "id": "06b38517",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ddef2",
   "metadata": {
    "id": "444ddef2"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def translate_text_bhashini(input_text):\n",
    "    url = \"https://dhruva-api.bhashini.gov.in/services/inference/pipeline\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"pipelineTasks\": [\n",
    "            {\n",
    "                \"taskType\": \"translation\",\n",
    "                \"config\": {\n",
    "                    \"language\": {\n",
    "                        \"sourceLanguage\": \"hi\",\n",
    "                        \"targetLanguage\": \"en\"\n",
    "                    },\n",
    "                    \"serviceId\": \"ai4bharat/indictrans-v2-all-gpu--t4\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"inputData\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"source\": input_text\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    })\n",
    "    headers = {\n",
    "        'Accept': '*/*',\n",
    "        'User-Agent': 'Thunder Client (https://www.thunderclient.com)',\n",
    "        'Authorization': 'sLAFJehUCZQ72NIM4nDZNCya7TQVzittLgJEU0vIf-69rp0gFUcGu5sjwAaOSUfa',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    retries = 0\n",
    "    max_retries = 5\n",
    "    start_time = time.time()\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, data=payload)\n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                translated_output = json.loads(response.text)['pipelineResponse'][0]['output'][0]['target']\n",
    "                end_time = time.time()\n",
    "                return translated_output, retries, end_time - start_time\n",
    "            else:\n",
    "                print(f\"Request failed with status code {response.status_code}. Retrying...\")\n",
    "                retries += 1\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}. Retrying...\")\n",
    "            retries += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    return \"Translation failed after maximum retries.\", max_retries, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ec581-fa82-40aa-9890-650e12ebee9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7585146-5f5e-4e83-af4c-3d65a0e7ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48ff3f-6e89-440c-b204-5d24f6495cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "input_folder='output\\\\hindi'\n",
    "all_files=[]\n",
    "for folder, subfolders, files in os.walk(input_folder):\n",
    "    full_file_paths = [os.path.join(folder, file) for file in files]\n",
    "    all_files.extend(full_file_paths)\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9758aa-c338-4ea6-938c-a407b2f00e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(all_files[0])\n",
    "newdf=pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07babb3f-499c-4bfb-9196-96abb2c48c11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed882e6a-bd06-4a0b-b386-07cb12c911f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'content': 'originalLanguageChunk','heading':'originalLanguageHeading'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ff27e-0408-49a3-9d12-3f83c6edf7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('translating')\n",
    "df['content'] = df.apply(lambda row: translate_text_bhashini(row['originalLanguageChunk'])[0] if row['contentType'] != 'table' else row['originalLanguageChunk'], axis=1)\n",
    "df['heading'] = df.apply(lambda row: translate_text_bhashini(row['originalLanguageHeading'])[0] if row['contentType'] != 'table' else row['originalLanguageHeading'], axis=1)\n",
    "print('\\rtranslating done')\n",
    "df=df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d30074-f7a4-48e8-8795-f803494598d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['chunkId','content','heading','originalLanguageChunk','StartPage','EndPage','originalLanguageHeading','ContentWordCount','pdfName','contentType','image','summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc3f64a-d49e-45cb-adf6-25ab8094c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d4ca5-39f3-4ad8-8c1d-0a63ee1e2e76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Splitting bigger chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74087e4-8161-4c91-94d7-01ee2d5d9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c3d65-6506-4ff3-88fb-214037a52e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('output/english\\\\FARMER PRODUCER ORGANISATIONS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26edc214-709f-4ff7-978f-23094e5a1eeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "count=0\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    \n",
    "    word_count = row['ContentWordCount']\n",
    "    content = row['content']\n",
    "    \n",
    "    # Check if ContentWordCount is greater than 200\n",
    "    if int(word_count) > 200 and row['contentType']=='para':\n",
    "        # Split the content into chunks of <= 200 words with complete sentences\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', content)\n",
    "        \n",
    "        \n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        for sentence in sentences:\n",
    "            # print(sentence)\n",
    "            \n",
    "            temp=' '.join(current_chunk + [sentence])\n",
    "            if len(temp.split()) <= 200:\n",
    "                current_chunk.append(sentence)\n",
    "                # print(current_chunk)\n",
    "                \n",
    "            else:\n",
    "                chunks.append(' '.join(current_chunk))\n",
    "                current_chunk = [sentence]\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "\n",
    "        # Create new rows for each chunk\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            count+=1\n",
    "            new_row = {\n",
    "                'chunkId': index,  # You may need to assign a new chunkId\n",
    "                'content': chunk,\n",
    "                'heading': row['heading'],\n",
    "                'originalLanguageChunk': row['originalLanguageChunk'],\n",
    "                'StartPage': row['StartPage'],\n",
    "                'EndPage': row['EndPage'],\n",
    "                'originalLanguageHeading': row['originalLanguageHeading'],\n",
    "                'ContentWordCount': len(chunk.split()),\n",
    "                'pdfName': row['pdfName'],\n",
    "                'contentType': row['contentType'],\n",
    "                'image': row['image'],\n",
    "                'summary': row['summary']\n",
    "            }\n",
    "            new_rows.append(new_row)\n",
    "    else:\n",
    "        # If ContentWordCount is <= 200, keep the row as it is\n",
    "        count+=1\n",
    "        new_rows.append({\n",
    "            'chunkId': count,\n",
    "            'content': content,\n",
    "            'heading': row['heading'],\n",
    "            'originalLanguageChunk': row['originalLanguageChunk'],\n",
    "            'StartPage': row['StartPage'],\n",
    "            'EndPage': row['EndPage'],            \n",
    "            'originalLanguageHeading': row['originalLanguageHeading'],\n",
    "            'ContentWordCount': word_count,\n",
    "            'pdfName': row['pdfName'],\n",
    "            'contentType': row['contentType'],\n",
    "            'image': row['image'],\n",
    "            'summary': row['summary']\n",
    "        })\n",
    "\n",
    "# Create a new DataFrame with the updated rows\n",
    "new_df = pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6d807-89cb-4955-bcc5-a6c8f079978a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b030e9e-0583-437f-ac9d-d4f8fe93767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16294287-d164-4714-a618-410323317645",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"and Rural Development National Bank for Agriculture Mumbai  2015 Title                               :                                  Farmer Producer Organisations - Frequently Asked Questions (FAQs)   Written and Published by                               :                                  Farm Sector Policy Department & Farm Sector                                   Development Department, NABARD Head Office, Mumbai  Date of Publishing                               :                                  March 2015 Design & Printing                               :                                  M/s Image Impression Contact                               :                                  Plot No C-24, 'G' Block, Bandra Kurla Complex,                                  Bandra East, Mumbai - 400051.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a2c6c-195f-4da0-b2ad-483be45c1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=' '.join(current_chunk + [sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334220a-80d1-46ab-8de9-1afb42a60793",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db901872-369a-4fa9-a9d1-2d9fbc9b0c66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1157a-b64d-44e0-b6eb-f432d8d409e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "def split_chunks(df,upper_limit=180):\n",
    "    new_rows = []\n",
    "    count=0\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "    \n",
    "        word_count = row['ContentWordCount']\n",
    "        content = row['content']\n",
    "        \n",
    "        if int(word_count) > upper_limit and row['contentType']=='para':\n",
    "            sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', content)\n",
    "            \n",
    "            \n",
    "            chunks = []\n",
    "            current_chunk = []\n",
    "            for sentence in sentences:\n",
    "                # print(sentence)\n",
    "                \n",
    "                temp=' '.join(current_chunk + [sentence])\n",
    "                if len(temp.split()) <= upper_limit:\n",
    "                    current_chunk.append(sentence)\n",
    "                    # print(current_chunk)\n",
    "                    \n",
    "                else:\n",
    "                    chunks.append(' '.join(current_chunk))\n",
    "                    current_chunk = [sentence]\n",
    "            \n",
    "            if current_chunk:\n",
    "                chunks.append(' '.join(current_chunk))\n",
    "    \n",
    "            \n",
    "            \n",
    "            for chunk in chunks:\n",
    "                count+=1\n",
    "                new_row = {\n",
    "                    'chunkId': index,  \n",
    "                    'content': chunk,\n",
    "                    'heading': row['heading'],\n",
    "                    'originalLanguageChunk': row['originalLanguageChunk'],\n",
    "                    'StartPage': row['StartPage'],\n",
    "                    'EndPage': row['EndPage'],\n",
    "                    'originalLanguageHeading': row['originalLanguageHeading'],\n",
    "                    'ContentWordCount': len(chunk.split()),\n",
    "                    'pdfName': row['pdfName'],\n",
    "                    'contentType': row['contentType'],\n",
    "                    'image': row['image'],\n",
    "                    'summary': row['summary']\n",
    "                }\n",
    "                new_rows.append(new_row)\n",
    "        else:\n",
    "           \n",
    "            count+=1\n",
    "            new_rows.append({\n",
    "                    'chunkId': count,\n",
    "                    'content': content,\n",
    "                    'heading': row['heading'],\n",
    "                    'originalLanguageChunk': row['originalLanguageChunk'],\n",
    "                    'StartPage': row['StartPage'],\n",
    "                    'EndPage': row['EndPage'],            \n",
    "                    'originalLanguageHeading': row['originalLanguageHeading'],\n",
    "                    'ContentWordCount': word_count,\n",
    "                    'pdfName': row['pdfName'],\n",
    "                    'contentType': row['contentType'],\n",
    "                    'image': row['image'],\n",
    "                    'summary': row['summary']\n",
    "            })\n",
    "\n",
    "\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12f2b2-0ef0-4255-888e-04f124e65894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('output/english\\\\NFSM12102018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c2e86-6ae0-4688-b436-986d06dec2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=split_chunks(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752eeb7-3949-4b5c-94bc-32bcd8b2a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656700a-ad66-42f0-9287-a307c2912c41",
   "metadata": {},
   "source": [
    "# Joining Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "00b2451a-2ffe-49f6-8e6e-61053bd8fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('output/english/Revised_Operational_Guidelines_new.csv')\n",
    "df['status']='visited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "86387f62-104b-4fc5-aa0b-f7ce42fa5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f66d6b90-22f5-48d6-a5c7-0a8b641f3911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%\n"
     ]
    }
   ],
   "source": [
    "print('%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "08de4bdd-63b4-4b56-8bbc-3f6f9e80f555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "here\n",
      "reached\n",
      "here\n",
      "reached\n",
      "here\n",
      "reached\n",
      "here\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m     prev_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munvisited\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m valid_word_count:\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnext_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     62\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContentWordCount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mnext_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContentWordCount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     63\u001b[0m     next_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munvisited\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "rows = df.to_dict(orient='records')\n",
    "size=len(rows)\n",
    "i=0\n",
    "lowerLimit=40\n",
    "while i<size:\n",
    "    \n",
    "    row=rows[i]\n",
    "    if row['status']=='unvisited':\n",
    "        i+=1\n",
    "        continue\n",
    "    # print(row['chunkId'])\n",
    "    print(i)\n",
    "    prev_row=rows[i-1] if i>0 else None\n",
    "    next_row=rows[i+1] if i<size-1 else None\n",
    "    \n",
    "    # if type(str(next_row))=='pandas.core.series.Series':\n",
    "\n",
    "    # merged_rows = []\n",
    "    # current_row = None\n",
    "    temp=1\n",
    "    while row['ContentWordCount']<lowerLimit:\n",
    "        print('here')\n",
    "        \n",
    "        if isinstance(next_row, dict):\n",
    "            \n",
    "            same_type=(row['contentType']==next_row['contentType'])\n",
    "            same_heading=row['heading']==next_row['heading']\n",
    "            valid_word_count=row['ContentWordCount']+next_row['ContentWordCount']<200 \n",
    "        else:\n",
    "            same_type=same_heading=valid_word_count=False            \n",
    "        if isinstance(prev_row, dict):\n",
    "            psame_type=(row['contentType']==prev_row['contentType'])\n",
    "            psame_heading=(row['heading']==prev_row['heading'])\n",
    "            pvalid_word_count=row['ContentWordCount']+prev_row['ContentWordCount']<200\n",
    "        else:\n",
    "            psame_type=psame_heading=pvalid_word_count=False\n",
    "       \n",
    "        if  same_type and same_heading and valid_word_count:\n",
    "            print('here')\n",
    "            row['content']+=next_row['content']\n",
    "            row['ContentWordCount']+=next_row['ContentWordCount']\n",
    "            next_row['status']='unvisited'\n",
    "            \n",
    "        # elif same_type and not same_heading:\n",
    "        elif psame_type and psame_heading and pvalid_word_count:\n",
    "            row['content']+=prev_row['content']\n",
    "            row['ContentWordCount']+=prev_row['ContentWordCount']\n",
    "            prev_row['status']='unvisited'\n",
    "\n",
    "        elif valid_word_count and same_heading:\n",
    "            row['content']+=next_row['content']\n",
    "            row['ContentWordCount']+=next_row['ContentWordCount']\n",
    "            next_row['status']='unvisited'\n",
    "\n",
    "        elif pvalid_word_count and psame_heading:\n",
    "            row['content']+=prev_row['content']\n",
    "            row['ContentWordCount']+=prev_row['ContentWordCount']\n",
    "            prev_row['status']='unvisited'\n",
    "\n",
    "        elif valid_word_count:\n",
    "            row['content']+=(next_row['content'])\n",
    "            row['ContentWordCount']+=next_row['ContentWordCount']\n",
    "            next_row['status']='unvisited'\n",
    "            merged=str(row['heading'])+','+str(next_row['heading'])\n",
    "            merged=list(set(merged.split(',')))\n",
    "            \n",
    "            row['heading']=','.join(merged)\n",
    "        \n",
    "        elif pvalid_word_count:\n",
    "            row['content']+=prev_row['content']\n",
    "            row['ContentWordCount']+=prev_row['ContentWordCount']\n",
    "            prev_row['status']='unvisited'\n",
    "            merged=str(row['heading'])+','+str(prev_row['heading'])\n",
    "            merged=list(set(merged.split(',')))\n",
    "            # row['heading']=','.join(list(set([(row['heading']+','+prev_row['heading'])].split(','))))\n",
    "\n",
    "        else:\n",
    "            print('reached')\n",
    "            temp+=1\n",
    "            \n",
    "            prev_row=rows[i-temp] if i>temp-1 else None\n",
    "            # print(prev_row)\n",
    "            # break\n",
    "            next_row=rows[i+temp] if i<size-temp else None\n",
    "            # print(prev_row)\n",
    "            \n",
    "    # break\n",
    "            # temp+=1\n",
    "            # if i>temp-1:\n",
    "            #     prev_row=rows[i-temp]\n",
    "            # else:\n",
    "            #     prev_row=None\n",
    "            # next_row=rows[i+temp] if i<size-temp else None\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1b3e6e9c-a6f5-49af-98e4-1118ea6a5adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = ['Unnamed: 0', 'chunkId', 'content', 'heading', 'originalLanguageChunk', 'StartPage', 'EndPage', 'originalLanguageHeading', 'ContentWordCount', 'pdfName', 'contentType', 'image', 'summary', 'status']\n",
    "\n",
    "# Create DataFrame\n",
    "new_df = pd.DataFrame(rows, columns=columns)\n",
    "new_df = new_df[new_df['status']=='visited']\n",
    "new_df=new_df.drop(columns=['Unnamed: 0','status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5878cbcd-46d4-468f-8931-d8d632995327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5d6d3436-1b5c-4f25-bbda-36ca96300698",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0', 'status'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_df\u001b[38;5;241m=\u001b[39m\u001b[43mnew_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstatus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0', 'status'] not found in axis\""
     ]
    }
   ],
   "source": [
    "new_df=new_df.drop(columns=['Unnamed: 0','status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "920e732f-6b2f-4c39-ac1d-fee9e08a6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('output/english/FPO_Scheme_Guidelines_FINAL_English_splitted_merged.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678cc3c-2d0e-4b16-9b75-97d5b5b0fe39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73012814-15b9-4bb3-b233-66fc0e2586f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key=os.environ.get(\"API_KEY\")\n",
    "\n",
    "def get_gpt_response(system_prompt,user_prompt):\n",
    "  response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-1106\", temperature = 0,\n",
    "                messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                          {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ])\n",
    "  gpt_response =  response[\"choices\"][0][\"message\"][\"content\"]\n",
    "  return(gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f229ff-b621-4a7d-a653-afdb1a4fa46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = \"\"\"You are an AI bot that summarises user provided content in 5 sentences.\n",
    "The content that you are shared is part of the Samagra Processes and Policy Corpus. The data was extracted from the PDF and has two sections - Heading and Content.\n",
    "These will be provided to you to summarize in the folloowing format\n",
    "\n",
    "Heading: <Heading>\n",
    "Content: <Content>\n",
    "\n",
    "You dont say anything else apart from the 5 sentence summary. Do not reproduce either the Heading or Content.\n",
    "\"\"\"\n",
    "file='E:\\PDF-Parser\\output\\english\\FARMER PRODUCER ORGANISATIONS.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "df['summary'] = ''\n",
    "for i in range(df.shape[0]):\n",
    "    print(i)\n",
    "    if df.loc[i,'contentType']!='heading':\n",
    "        content = \"Heading:\" + str(df.loc[i,'heading']) + \"\\n\" + \"Content: \" + str(df.loc[i,'content'])\n",
    "    \n",
    "        df.loc[i,'summary'] =  get_gpt_response(system_prompt,content)\n",
    "df.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5aadd-e6d0-4603-b4be-6343ffa21d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary('E:\\PDF-Parser\\output\\english\\FARMER PRODUCER ORGANISATIONS.csv')\n",
    "df.loc[0,'contentType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929179c8-d0d7-4029-9169-c7335c4a0752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79b88a-b77b-43cd-843c-8e06dcbf5d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3a920-5c40-44af-911f-8c705c56bd29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1e4f9-4fe1-4a85-970b-8e64b495fdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c50bb74",
   "metadata": {
    "id": "8c50bb74"
   },
   "source": [
    "# DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4e006",
   "metadata": {
    "id": "03c4e006"
   },
   "outputs": [],
   "source": [
    "combined_chunks = []\n",
    "inside_table = False\n",
    "current_table = ''\n",
    "\n",
    "for chunk in chunks:\n",
    "    if inside_table:\n",
    "        # Check if the current chunk is the end of the table\n",
    "        if chunk.startswith('|'):\n",
    "            inside_table = True\n",
    "            current_table=current_table+'\\n'+chunk\n",
    "        else:\n",
    "            combined_chunks.append(current_table)\n",
    "            combined_chunks.append(chunk)\n",
    "            inside_table=False\n",
    "    elif chunk.startswith('|'):\n",
    "        inside_table = True\n",
    "        current_table=chunk\n",
    "#     elif chunk=='':\n",
    "#         continue\n",
    "    else:\n",
    "        combined_chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859541e",
   "metadata": {
    "id": "b859541e"
   },
   "outputs": [],
   "source": [
    "inside_pair=False\n",
    "current_pair=''\n",
    "for chunk in combined_chunks:\n",
    "    if chunk['type']=='heading':\n",
    "        iside_pair=True\n",
    "    elif chunk['type']=='para':\n",
    "        if inside_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7958a",
   "metadata": {
    "id": "6da7958a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in combined_chunks:\n",
    "    print(i,end='\\n************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68bd85d",
   "metadata": {
    "id": "b68bd85d"
   },
   "source": [
    "## GPT Stuff (No use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043bef7c",
   "metadata": {
    "id": "043bef7c"
   },
   "outputs": [],
   "source": [
    "from markdown_it import MarkdownIt\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69770d01",
   "metadata": {
    "id": "69770d01"
   },
   "outputs": [],
   "source": [
    "file='Value_chain_financing.md'\n",
    "file=open(file,'r',encoding='utf-8')\n",
    "md_text=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d398f7f",
   "metadata": {
    "id": "3d398f7f"
   },
   "outputs": [],
   "source": [
    "from markdown_it import MarkdownIt\n",
    "\n",
    "def md_to_html(md_file_path, html_file_path):\n",
    "    # Read Markdown content from file\n",
    "    with open(md_file_path, 'r', encoding='utf-8') as md_file:\n",
    "        md_text = md_file.read()\n",
    "    md = MarkdownIt()\n",
    "    html_content = md.render(md_text)\n",
    "    with open(html_file_path, 'w', encoding='utf-8') as html_file:\n",
    "        html_file.write(html_content)\n",
    "\n",
    "md_path = \"Value_chain_financing.md\"\n",
    "html_path = \"output.html\"\n",
    "md_to_html(md_path, html_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb6b2f",
   "metadata": {
    "id": "cceb6b2f"
   },
   "outputs": [],
   "source": [
    "file=open('output.html', 'r', encoding='utf-8')\n",
    "html_content = file.read()\n",
    "page_data = {}\n",
    "current_main_heading = ''\n",
    "current_subheading = ''\n",
    "crop_soup = BeautifulSoup(html_content, 'html.parser')\n",
    "# print(crop_soup)\n",
    "tags = crop_soup.find_all(['h4','h1','h2','h3', 'p', 'li','table'])\n",
    "\n",
    "for tag in tags:\n",
    "    if tag.name == 'h4':\n",
    "        current_main_heading = tag.text.strip()\n",
    "        current_subheading = ''  # Reset subheading when a new main heading is found\n",
    "        if current_main_heading not in page_data:\n",
    "            page_data[current_main_heading] = {}\n",
    "    elif tag.name == 'p' and tag.find('strong'):\n",
    "        current_subheading = tag.text.strip()\n",
    "        if current_main_heading not in page_data:\n",
    "            page_data[current_main_heading] = {}\n",
    "        if current_subheading not in page_data[current_main_heading]:\n",
    "            page_data[current_main_heading][current_subheading] = []\n",
    "    elif current_main_heading and current_subheading:\n",
    "        # Only add content if both main heading and subheading are available\n",
    "        if tag.name=='table':\n",
    "            data=table_parser(tag)\n",
    "        else:\n",
    "            data=tag.text.strip()\n",
    "        page_data[current_main_heading][current_subheading].append(data)\n",
    "\n",
    "\n",
    "    else:\n",
    "        if current_main_heading and not current_subheading:\n",
    "            current_subheading='General'\n",
    "            page_data[current_main_heading][current_subheading]=[]\n",
    "        if not current_main_heading and not current_subheading:\n",
    "            current_main_heading='General'\n",
    "            current_subheading='General'\n",
    "            page_data[current_main_heading]={}\n",
    "            page_data[current_main_heading][current_subheading]=[]\n",
    "        if tag.name=='table':\n",
    "            data=table_parser(tag)\n",
    "        else:\n",
    "            data=tag.text.strip()\n",
    "        page_data[current_main_heading][current_subheading].append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e636b8",
   "metadata": {
    "id": "11e636b8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690703f6",
   "metadata": {
    "id": "690703f6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md = MarkdownIt()\n",
    "tokens = md.parse(md_text)\n",
    "\n",
    "headers = []\n",
    "current_header = None\n",
    "\n",
    "for token in tokens:\n",
    "    print(token,end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d788e",
   "metadata": {
    "id": "de3d788e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
